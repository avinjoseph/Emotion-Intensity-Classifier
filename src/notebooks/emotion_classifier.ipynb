{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42879a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\avin5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\avin5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.data_preprocessing import DataPreprocessor\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "from utils.emotion_regressor import EmotionRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import nlpaug.augmenter.word as naw\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7e4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_b_00001</td>\n",
       "      <td>colorado middle of nowhere</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_b_00002</td>\n",
       "      <td>this involved swimming a pretty large lake tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_b_00003</td>\n",
       "      <td>it was one of my most shameful experiences</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_b_00004</td>\n",
       "      <td>after all i had vegetables coming out my ears ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_b_00005</td>\n",
       "      <td>then the screaming started</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>eng_train_track_b_02764</td>\n",
       "      <td>she cants her hip against my waist into my sid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>eng_train_track_b_02765</td>\n",
       "      <td>i then did the dishes whitened my teeth watche...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>eng_train_track_b_02766</td>\n",
       "      <td>it just kind of gradually vanished over a coup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>eng_train_track_b_02767</td>\n",
       "      <td>i didnt look out of my hands</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>eng_train_track_b_02768</td>\n",
       "      <td>im fine amanda said forcefully shrugging off h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0     eng_train_track_b_00001   \n",
       "1     eng_train_track_b_00002   \n",
       "2     eng_train_track_b_00003   \n",
       "3     eng_train_track_b_00004   \n",
       "4     eng_train_track_b_00005   \n",
       "...                       ...   \n",
       "2763  eng_train_track_b_02764   \n",
       "2764  eng_train_track_b_02765   \n",
       "2765  eng_train_track_b_02766   \n",
       "2766  eng_train_track_b_02767   \n",
       "2767  eng_train_track_b_02768   \n",
       "\n",
       "                                                   text  anger  fear  joy  \\\n",
       "0                            colorado middle of nowhere      0     1    0   \n",
       "1     this involved swimming a pretty large lake tha...      0     2    0   \n",
       "2            it was one of my most shameful experiences      0     1    0   \n",
       "3     after all i had vegetables coming out my ears ...      0     0    0   \n",
       "4                            then the screaming started      0     3    0   \n",
       "...                                                 ...    ...   ...  ...   \n",
       "2763  she cants her hip against my waist into my sid...      0     0    2   \n",
       "2764  i then did the dishes whitened my teeth watche...      0     0    0   \n",
       "2765  it just kind of gradually vanished over a coup...      0     0    0   \n",
       "2766                       i didnt look out of my hands      0     1    0   \n",
       "2767  im fine amanda said forcefully shrugging off h...      1     0    0   \n",
       "\n",
       "      sadness  surprise  \n",
       "0           0         1  \n",
       "1           0         0  \n",
       "2           3         0  \n",
       "3           0         0  \n",
       "4           1         2  \n",
       "...       ...       ...  \n",
       "2763        0         1  \n",
       "2764        0         0  \n",
       "2765        0         1  \n",
       "2766        0         0  \n",
       "2767        0         0  \n",
       "\n",
       "[2768 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataPreprocessor('../data/track-b.csv')\n",
    "df.preprocess()\n",
    "data = df.data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f2a58",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "As the number of samples are pretty low i.e 2768 samples, the model performance will be very poor due to insufficient data. Here we are using a data augmentation method using a nlpaug library. There are several other methods for augmenting the data.\n",
    "\n",
    "Data augmentation may or may not improve the performance of the model. In our approach it helps to imporve the model performance drastically.\n",
    "NLPAug library offers three type of augmentation like character level, word level and Sentence level. Generating more augmented data will also costs the model performance, here we are trying to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "augmenter = naw.SynonymAug(aug_src='wordnet', aug_p=0.2)\n",
    "augmented_rows = []\n",
    "\n",
    "emotion_columns = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
    "\n",
    "# Loop through each row in the original dataset\n",
    "for idx, row in data.iterrows():\n",
    "    original_text = str(row['text'])\n",
    "    \n",
    "    try:\n",
    "        augmented_text = augmenter.augment(original_text)\n",
    "    except:\n",
    "        augmented_text = original_text\n",
    "\n",
    "    # Only add if augmentation changed the sentence\n",
    "    if augmented_text != original_text:\n",
    "        new_row = {\n",
    "            'id': f\"{row['id']}_aug\",  # Append _aug to indicate it's synthetic\n",
    "            'text': augmented_text\n",
    "        }\n",
    "        # Copy emotion intensities\n",
    "        for emo in emotion_columns:\n",
    "            new_row[emo] = row[emo]\n",
    "        augmented_rows.append(new_row)\n",
    "\n",
    "aug_df = pd.DataFrame(augmented_rows)\n",
    "combined_df = pd.concat([data, aug_df], ignore_index=True)\n",
    "\n",
    "# Save to new CSV\n",
    "# combined_df.to_csv(\"dataset_augmented.csv\", index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_b_00001</td>\n",
       "      <td>colorado middle of nowhere</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_b_00002</td>\n",
       "      <td>this involved swimming a pretty large lake tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_b_00003</td>\n",
       "      <td>it was one of my most shameful experiences</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_b_00004</td>\n",
       "      <td>after all i had vegetables coming out my ears ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_b_00005</td>\n",
       "      <td>then the screaming started</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>eng_train_track_b_02764_aug</td>\n",
       "      <td>she cants her hip against my waist into my sid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>eng_train_track_b_02765_aug</td>\n",
       "      <td>i then did the dishes whitened my dentition wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>eng_train_track_b_02766_aug</td>\n",
       "      <td>information technology just kind of gradually ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>eng_train_track_b_02767_aug</td>\n",
       "      <td>i didnt wait out of my hands</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>eng_train_track_b_02768_aug</td>\n",
       "      <td>im fine amanda read forcefully shrug off her hand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5536 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0         eng_train_track_b_00001   \n",
       "1         eng_train_track_b_00002   \n",
       "2         eng_train_track_b_00003   \n",
       "3         eng_train_track_b_00004   \n",
       "4         eng_train_track_b_00005   \n",
       "...                           ...   \n",
       "5531  eng_train_track_b_02764_aug   \n",
       "5532  eng_train_track_b_02765_aug   \n",
       "5533  eng_train_track_b_02766_aug   \n",
       "5534  eng_train_track_b_02767_aug   \n",
       "5535  eng_train_track_b_02768_aug   \n",
       "\n",
       "                                                   text  anger  fear  joy  \\\n",
       "0                            colorado middle of nowhere      0     1    0   \n",
       "1     this involved swimming a pretty large lake tha...      0     2    0   \n",
       "2            it was one of my most shameful experiences      0     1    0   \n",
       "3     after all i had vegetables coming out my ears ...      0     0    0   \n",
       "4                            then the screaming started      0     3    0   \n",
       "...                                                 ...    ...   ...  ...   \n",
       "5531  she cants her hip against my waist into my sid...      0     0    2   \n",
       "5532  i then did the dishes whitened my dentition wa...      0     0    0   \n",
       "5533  information technology just kind of gradually ...      0     0    0   \n",
       "5534                       i didnt wait out of my hands      0     1    0   \n",
       "5535  im fine amanda read forcefully shrug off her hand      1     0    0   \n",
       "\n",
       "      sadness  surprise  \n",
       "0           0         1  \n",
       "1           0         0  \n",
       "2           3         0  \n",
       "3           0         0  \n",
       "4           1         2  \n",
       "...       ...       ...  \n",
       "5531        0         1  \n",
       "5532        0         0  \n",
       "5533        0         1  \n",
       "5534        0         0  \n",
       "5535        0         0  \n",
       "\n",
       "[5536 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = DataPreprocessor('../data/dataset_augmented.csv')\n",
    "pre.preprocess()\n",
    "aug_data = pre.data\n",
    "aug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Here we are using multilabel stratified split to ensure that the distribution of emotions is similar in both training and validation sets.\n",
    "# This is important for multi-label classification tasks to ensure that each emotion is represented in both sets.\n",
    "# If we use train test split, it may lead to imbalanced classes in the training and validation sets, which can affect the model's performance.\n",
    "# We will use the DistilBertTokenizerFast to tokenize the text data.\n",
    "\n",
    "X = aug_data[\"text\"]  # This should already be a Series\n",
    "y = aug_data[[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].values\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "for train_idx, val_idx in msss.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "train_dataset = EmotionDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = EmotionDataset(X_val, y_val, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0848cf",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "- This function trains the model for a specified number of epochs, monitors validation loss, a\n",
    "- different hyperparameters can be adjusted to improve performance.\n",
    "- It uses a linear learning rate scheduler and implements early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=16, patience=3, learning_rate=2e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=int(0.1 * total_steps), \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41431fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:11<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6088 | Val Loss = 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:11<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.3649 | Val Loss = 0.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:11<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.2486 | Val Loss = 0.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:11<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.1799 | Val Loss = 0.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:12<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.1413 | Val Loss = 0.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:12<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.1137 | Val Loss = 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:12<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.1001 | Val Loss = 0.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:13<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.0878 | Val Loss = 0.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.0808 | Val Loss = 0.1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [01:15<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.0772 | Val Loss = 0.1702\n"
     ]
    }
   ],
   "source": [
    "# EmotionRegressor is a custom model defined in utils/emotion_regressor.py\n",
    "# It should inherit from nn.Module and implement the forward method.\n",
    "model = EmotionRegressor(dropout=0.5)\n",
    "trained_model = train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=16, patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba83ed",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "- Evaluation function to compute MAE, RMSE, and RÂ² for the trained model\n",
    "- It is a good metric to evaluate the performance of regression models, especially in multi-label settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(preds, labels, emotion_labels=[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]):\n",
    "    for i, emotion in enumerate(emotion_labels):\n",
    "        mae = mean_absolute_error(labels[:, i], preds[:, i])\n",
    "        rmse = np.sqrt(mean_squared_error(labels[:, i], preds[:, i]))\n",
    "        r2 = r2_score(labels[:, i], preds[:, i])\n",
    "        print(f\"\\nðŸ§  Emotion: {emotion}\")\n",
    "        print(f\"   - MAE:  {mae:.4f}\")\n",
    "        print(f\"   - RMSE: {rmse:.4f}\")\n",
    "        print(f\"   - RÂ²:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Emotion: anger\n",
      "   - MAE:  0.1592\n",
      "   - RMSE: 0.3323\n",
      "   - RÂ²:   0.6604\n",
      "\n",
      "ðŸ§  Emotion: fear\n",
      "   - MAE:  0.3523\n",
      "   - RMSE: 0.5099\n",
      "   - RÂ²:   0.7341\n",
      "\n",
      "ðŸ§  Emotion: joy\n",
      "   - MAE:  0.1851\n",
      "   - RMSE: 0.3512\n",
      "   - RÂ²:   0.7521\n",
      "\n",
      "ðŸ§  Emotion: sadness\n",
      "   - MAE:  0.2750\n",
      "   - RMSE: 0.4612\n",
      "   - RÂ²:   0.6998\n",
      "\n",
      "ðŸ§  Emotion: surprise\n",
      "   - MAE:  0.2397\n",
      "   - RMSE: 0.3872\n",
      "   - RÂ²:   0.6803\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_loader is your DataLoader for test set\n",
    "test_loader = DataLoader(val_dataset, batch_size=16)  # Using validation set as test set for demonstration\n",
    "preds, labels = evaluate_model(trained_model, test_loader )\n",
    "print_metrics(preds, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5ccb1",
   "metadata": {},
   "source": [
    "\n",
    "| Emotion   | MAE   | RMSE  | RÂ²    | Performance Summary\n",
    "|-----------|-------|-------|-------|----------------------\n",
    "| Anger     | 0.159 | 0.332 | 0.660 | Very low error; slightly lower RÂ²\n",
    "| Fear      | 0.352 | 0.510 | 0.734 | Highest MAE; decent RÂ² (still good)\n",
    "| Joy       | 0.185 | 0.351 | 0.752 | Very balanced and strong\n",
    "| Sadness   | 0.275 | 0.461 | 0.700 | Medium performance\n",
    "| Surprise  | 0.240 | 0.387 | 0.680 | Decent generalization\n",
    "\n",
    "\n",
    " Key Observations:\n",
    "\n",
    "- Joy shows the best RÂ² (0.75) and low errors â†’ The model predicts it well.\n",
    "\n",
    "- Anger has the lowest MAE (0.1592) â†’ Very accurate predictions.\n",
    "\n",
    "- Fear has the highest MAE/RMSE â†’ Might benefit from:\n",
    "\n",
    "More balanced training samples for \"fear\"\n",
    "\n",
    "Targeted augmentation focused on fearful contexts\n",
    "\n",
    "- Sadness & Surprise are in the middle â€” good, but could be fine-tuned further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2df329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model's state_dict\n",
    "# torch.save(model.state_dict(), \"emotion_classifier_model_2.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fa0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
